import numpy as np
from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt

# Define the training data: 5x3 matrices representing digits 0 to 9
digits = {
    0: [[1, 1, 1], [1, 0, 1], [1, 0, 1], [1, 0, 1], [1, 1, 1]],
    1: [[0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0]],
    2: [[1, 1, 1], [0, 0, 1], [1, 1, 1], [1, 0, 0], [1, 1, 1]],
    3: [[1, 1, 1], [0, 0, 1], [1, 1, 1], [0, 0, 1], [1, 1, 1]],
    4: [[1, 0, 1], [1, 0, 1], [1, 1, 1], [0, 0, 1], [0, 0, 1]],
    5: [[1, 1, 1], [1, 0, 0], [1, 1, 1], [0, 0, 1], [1, 1, 1]],
    6: [[1, 1, 1], [1, 0, 0], [1, 1, 1], [1, 0, 1], [1, 1, 1]],
    7: [[1, 1, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1]],
    8: [[1, 1, 1], [1, 0, 1], [1, 1, 1], [1, 0, 1], [1, 1, 1]],
    9: [[1, 1, 1], [1, 0, 1], [1, 1, 1], [0, 0, 1], [0, 0, 1]]
}

# Prepare training data
X_train = np.array([np.array(digit).flatten() for digit in digits.values()])
y_train = np.array(list(digits.keys()))

# Train the model
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# Define the test data: 5x3 matrices representing digits to be recognized
test_data = {
    "Test 1": [[1, 1, 1], [1, 0, 1], [1, 0, 1], [1, 0, 1], [1, 1, 1]],  # Digit 0
    "Test 2": [[0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0]],  # Digit 1
    "Test 3": [[1, 1, 1], [0, 0, 1], [1, 1, 1], [1, 0, 0], [1, 1, 1]],  # Digit 2
    # Add more test data for other digits...
}

X_test = np.array([np.array(digit).flatten() for digit in test_data.values()])

# Predict digits for test data
predictions = model.predict(X_test)
fig, axs = plt.subplots(len(test_data), 2, figsize=(8, 4 * len(test_data)))

for i, (test_name, digit) in enumerate(test_data.items()):
    axs[i, 0].imshow(np.array(digit), cmap='binary')
    axs[i, 0].axis('off')
    axs[i, 0].set_title(test_name)

    axs[i, 1].text(0.5, 0.5, f"Predicted: {predictions[i]}", ha='center', va='center', fontsize=12)
    axs[i, 1].axis('off')

plt.tight_layout()
plt.show()
